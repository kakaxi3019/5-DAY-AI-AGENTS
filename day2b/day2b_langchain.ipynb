{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "210776c3",
   "metadata": {},
   "source": [
    "# Day 2b - Agent å·¥å…·æœ€ä½³å®è·µï¼ˆLangChainå¯æœ¬åœ°è¿è¡Œç‰ˆï¼‰\n",
    "\n",
    "ğŸš€ **Agent å·¥å…·æ¨¡å¼ä¸æœ€ä½³å®è·µ**\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° 5 å¤© Agent è¯¾ç¨‹çš„ç¬¬äºŒå¤©ï¼\n",
    "\n",
    "åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†å®ç°ä¸ **çœŸå® MCP æœåŠ¡å™¨** çš„è¿æ¥ï¼Œå¹¶å¤„ç†å…·æœ‰ **äººæœºäº¤äº’ (Human-in-the-Loop)** çš„é•¿æ—¶é—´è¿è¡Œæ“ä½œã€‚\n",
    "\n",
    "**åŸç‰ˆ**: Google ADK Team  \n",
    "**æ”¹å†™**: LangChain å®ç° (é›†æˆå®˜æ–¹ MCP SDK)\n",
    "\n",
    "åœ¨æœ¬ç¬”è®°æœ¬ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•ï¼š\n",
    "\n",
    "- âœ… ä½¿ç”¨ `mcp` Python SDK è¿æ¥åˆ°çœŸå®çš„ MCP æœåŠ¡å™¨ (å¦‚ `@modelcontextprotocol/server-everything`)\n",
    "- âœ… å°† MCP å·¥å…·æ¡¥æ¥åˆ° LangChain Agent\n",
    "- âœ… å®ç° **äººæœºäº¤äº’ (Human-in-the-Loop)** å®¡æ‰¹å·¥ä½œæµ\n",
    "---\n",
    "**åŸç‰ˆ**: Google ADK Team (Kaggle 5-Day Agent Course)  \n",
    "**æ”¹å†™**: LangChain å®ç°\n",
    "> **â„¹ï¸ å£°æ˜**: æœ¬æ•™ç¨‹æ”¹ç¼–è‡ª Google [5-Day AI Agents Course](https://www.kaggle.com/learn-guide/5-day-agents)ï¼Œç”± LangChain é‡å†™ä»¥é€‚é…æœ¬åœ°è¿è¡Œã€‚å†…å®¹ä»…ä¾›å­¦ä¹ ç ”ç©¶ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9308cde8",
   "metadata": {},
   "source": [
    "## âš™ï¸ ç¬¬ 1 éƒ¨åˆ†ï¼šè®¾ç½® (Setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1250d27",
   "metadata": {},
   "source": [
    "### 1.1 åˆ‡æ¢å†…æ ¸\n",
    "- ç‚¹å‡»å³ä¸Šè§’çš„ Kernel (å†…æ ¸) é€‰æ‹©åŒºåŸŸã€‚\n",
    "- åœ¨åˆ—è¡¨ä¸­é€‰æ‹© Python (5-DAY-AGENTS)ã€‚\n",
    "\n",
    "> å…³äºå¦‚ä½•åˆå§‹åŒ–ç¯å¢ƒå’Œåˆ›å»ºå†…æ ¸ï¼Œè¯·æŸ¥çœ‹ [README å¦‚ä½•è¿è¡Œ](../README.md#å¦‚ä½•è¿è¡Œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c9f4c5",
   "metadata": {},
   "source": [
    "### 1.2 å®‰è£…ä¾èµ–\n",
    "é™¤äº† LangChainï¼Œæˆ‘ä»¬è¿˜éœ€è¦å®‰è£… `mcp` å®˜æ–¹ SDKã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d109a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¼˜é€‰ uv åŒ…ç®¡ç†å™¨\n",
    "!uv pip install langchain langchain-openai langchain-community python-dotenv mcp nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e01d7fc",
   "metadata": {},
   "source": [
    "### 1.3 å¯¼å…¥ä¾èµ–åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfe071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import getpass\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"âœ… ä¾èµ–åº“åŠ è½½å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a473302",
   "metadata": {},
   "source": [
    "### 1.4 é…ç½® API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6cb0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å…è®¸åœ¨ Jupyter ä¸­åµŒå¥—è¿è¡Œ asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv()\n",
    "\n",
    "def configure_api_keys():\n",
    "    \"\"\"åŠ è½½å¹¶éªŒè¯ API é…ç½®\"\"\"\n",
    "    model_name = os.environ.get(\"MODEL_NAME\")\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    base_url = os.environ.get(\"OPENAI_API_BASE\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"âŒ é”™è¯¯: æœªåœ¨ .env æ–‡ä»¶ä¸­æ‰¾åˆ° OPENAI_API_KEY\")\n",
    "        return None\n",
    "    \n",
    "    # æ‰“å°éƒ¨åˆ† Key ä»¥éªŒè¯ (éšè—æ•æ„Ÿä¿¡æ¯)\n",
    "    masked_key = f\"{api_key[:8]}...\" if api_key else \"None\"\n",
    "    print(f\"âœ… API Key å·²åŠ è½½: {masked_key}\")\n",
    "    print(f\"âœ… ä½¿ç”¨æ¨¡å‹: {model_name}\")\n",
    "    if base_url:\n",
    "        print(f\"âœ… API Base URL: {base_url}\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"api_key\": api_key,\n",
    "        \"base_url\": base_url,\n",
    "        \"extra_body\": json.loads(os.environ.get(\"EXTRA_BODY\", \"{}\"))\n",
    "    }\n",
    "\n",
    "config = configure_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984a1c95",
   "metadata": {},
   "source": [
    "## ğŸ§° ç¬¬ 2 éƒ¨åˆ†ï¼šè¿æ¥çœŸå® MCP æœåŠ¡å™¨\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ `npx` è¿è¡Œ `@modelcontextprotocol/server-everything`ï¼Œå¹¶é€šè¿‡ `mcp` Python SDKä¸ä¹‹é€šä¿¡ã€‚\n",
    "\n",
    "ä¸ºäº†è®© LangChain Agent èƒ½ä½¿ç”¨è¿™äº›å·¥å…·ï¼Œæˆ‘ä»¬éœ€è¦ç¼–å†™ä¸€ä¸ªç®€å•çš„é€‚é…å™¨ï¼Œå°† MCP å·¥å…·è½¬æ¢ä¸º LangChain å·¥å…·ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d2401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp import StdioServerParameters, ClientSession\n",
    "from mcp.client.stdio import stdio_client\n",
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel, create_model\n",
    "import inspect\n",
    "\n",
    "class MCPClientService:\n",
    "    def __init__(self, command, args):\n",
    "        self.server_params = StdioServerParameters(command=command, args=args)\n",
    "        self.session = None\n",
    "        self.exit_stack = None\n",
    "        self.read = None\n",
    "        self.write = None\n",
    "    \n",
    "    async def __aenter__(self):\n",
    "        # å»ºç«‹è¿æ¥\n",
    "        self.client_ctx = stdio_client(self.server_params)\n",
    "        self.read, self.write = await self.client_ctx.__aenter__()\n",
    "        \n",
    "        self.session_ctx = ClientSession(self.read, self.write)\n",
    "        self.session = await self.session_ctx.__aenter__()\n",
    "        \n",
    "        await self.session.initialize()\n",
    "        return self\n",
    "        \n",
    "    async def __aexit__(self, exc_type, exc_val, exc_tb):\n",
    "        if self.session_ctx:\n",
    "            await self.session_ctx.__aexit__(exc_type, exc_val, exc_tb)\n",
    "        if self.client_ctx:\n",
    "            await self.client_ctx.__aexit__(exc_type, exc_val, exc_tb)\n",
    "\n",
    "    async def get_langchain_tools(self, tool_filter=None):\n",
    "        \"\"\"è·å– MCP å·¥å…·å¹¶è½¬æ¢ä¸º LangChain å·¥å…·\"\"\"\n",
    "        if not self.session:\n",
    "            raise RuntimeError(\"Session not initialized\")\n",
    "            \n",
    "        mcp_tools_list = await self.session.list_tools()\n",
    "        langchain_tools = []\n",
    "        \n",
    "        for mcp_tool in mcp_tools_list.tools:\n",
    "            if tool_filter and mcp_tool.name not in tool_filter:\n",
    "                continue\n",
    "                \n",
    "            # print(f\"  - å‘ç°å·¥å…·: {mcp_tool.name}\")\n",
    "            \n",
    "            # åŠ¨æ€åˆ›å»ºå‚æ•° Schema\n",
    "            fields = {}\n",
    "            if mcp_tool.inputSchema and \"properties\" in mcp_tool.inputSchema:\n",
    "                for name, schema in mcp_tool.inputSchema[\"properties\"].items():\n",
    "                    # ç®€åŒ–å¤„ç†ï¼šé»˜è®¤è§†ä¸ºå­—ç¬¦ä¸²ï¼Œå®é™…åº”æ ¹æ® type æ˜ å°„\n",
    "                    fields[name] = (str, ... if name in mcp_tool.inputSchema.get(\"required\", []) else None)\n",
    "            \n",
    "            args_schema = create_model(f\"{mcp_tool.name}Schema\", **fields)\n",
    "            \n",
    "            # åˆ›å»ºåŒ…è£…å‡½æ•°\n",
    "            # åˆ›å»ºåŒ…è£…å‡½æ•°\n",
    "            # fix: ä½¿ç”¨å·¥å‚å‡½æ•°é¿å…é—­åŒ…å˜é‡æ•è·é—®é¢˜\n",
    "            def make_tool_func(tool_name):\n",
    "                async def _tool_func(**kwargs):\n",
    "                    # print(f\"    [MCPè°ƒç”¨] {tool_name} with {kwargs}\")\n",
    "                    result = await self.session.call_tool(tool_name, arguments=kwargs)\n",
    "                    \n",
    "                    # å¤„ç†æ–‡æœ¬å’Œå›¾åƒç»“æœ\n",
    "                    output = []\n",
    "                    for content in result.content:\n",
    "                        if content.type == 'text':\n",
    "                            output.append(content.text)\n",
    "                        elif content.type == 'image':\n",
    "                            output.append(f\"[Image: {content.mimeType}, data_len={len(content.data)}]\")\n",
    "                            \n",
    "                            # åœ¨ Notebook ç¯å¢ƒä¸‹ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡\n",
    "                            try:\n",
    "                                from IPython.display import display, Image\n",
    "                                import base64\n",
    "                                display(Image(data=base64.b64decode(content.data)))\n",
    "                            except ImportError:\n",
    "                                pass # é Notebook ç¯å¢ƒå¿½ç•¥\n",
    "                                \n",
    "                    return \"\\n\".join(output)\n",
    "                return _tool_func\n",
    "\n",
    "            _tool_func = make_tool_func(mcp_tool.name)\n",
    "\n",
    "            langchain_tools.append(StructuredTool.from_function(\n",
    "                func=None,\n",
    "                coroutine=_tool_func, # LangChain æ”¯æŒ async å·¥å…·\n",
    "                name=mcp_tool.name,\n",
    "                description=mcp_tool.description,\n",
    "                args_schema=args_schema\n",
    "            ))\n",
    "            \n",
    "        return langchain_tools\n",
    "\n",
    "print(\"âœ… MCPClientService ç±»å·²å®šä¹‰\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d849a",
   "metadata": {},
   "source": [
    "### 2.2 è¿æ¥å¹¶è·å–å·¥å…·\n",
    "ç°åœ¨æˆ‘ä»¬å¯åŠ¨æœåŠ¡å™¨å¹¶è·å– `getTinyImage` å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de17bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ³¨æ„ï¼šè¿™éœ€è¦ç³»ç»Ÿä¸­å®‰è£…äº† npm/npx\n",
    "mcp_service = MCPClientService(\n",
    "    command=\"npx\", \n",
    "    args=[\"-y\", \"@modelcontextprotocol/server-everything\"]\n",
    ")\n",
    "\n",
    "# æˆ‘ä»¬å°†åœ¨ä¸€ä¸ª async ä¸Šä¸‹æ–‡ä¸­è¿è¡Œ Agent\n",
    "async def setup_agent():\n",
    "    print(\"ğŸ”Œ æ­£åœ¨è¿æ¥ MCP æœåŠ¡å™¨...\")\n",
    "    async with mcp_service as service:\n",
    "        print(\"âœ… å·²è¿æ¥ã€‚æ­£åœ¨è·å–å·¥å…·...\")\n",
    "        \n",
    "        # è·å–å·¥å…· (åªç­›é€‰ getTinyImage)\n",
    "        tools = await service.get_langchain_tools(tool_filter=[\"getTinyImage\"])\n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½ {len(tools)} ä¸ªå·¥å…·: {[t.name for t in tools]}\")\n",
    "        \n",
    "        return tools\n",
    "\n",
    "# ç”±äº Notebook çš„ç”Ÿå‘½å‘¨æœŸï¼Œæˆ‘ä»¬è¿™é‡Œç®€å•æ¼”ç¤ºä»è¿æ¥ä¸­è·å–å·¥å…·å¯¹è±¡\n",
    "# å®é™… Agent è¿è¡Œæ—¶éœ€è¦ä¿æŒè¿æ¥å¼€å¯ã€‚æˆ‘ä»¬å°†æŠŠ Agent è¿è¡Œä¹Ÿæ”¾åœ¨ async å‡½æ•°ä¸­ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0051e3c4",
   "metadata": {},
   "source": [
    "### 2.3 è¿è¡Œä½¿ç”¨ MCP å·¥å…·çš„ Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06895875",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "async def run_image_agent_demo():\n",
    "    async with mcp_service as service:\n",
    "        # 1. è·å–å·¥å…·\n",
    "        tools = await service.get_langchain_tools(tool_filter=[\"getTinyImage\"])\n",
    "        \n",
    "        # 2. åˆå§‹åŒ– Agent\n",
    "        llm = ChatOpenAI(model=config[\"model_name\"], temperature=0.7)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"ä½ æ˜¯ä¸€ä¸ªåŠ©æ‰‹ã€‚è¯·ä½¿ç”¨å·¥å…·ç”Ÿæˆå›¾ç‰‡ã€‚\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "            (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "        ])\n",
    "        \n",
    "        agent = create_tool_calling_agent(llm, tools, prompt)\n",
    "        agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "        \n",
    "        # 3. è¿è¡Œ\n",
    "        print(\"\\nğŸ¤– User: ç”Ÿæˆä¸€å¼ ç¤ºä¾‹å°å›¾\")\n",
    "        response = await agent_executor.ainvoke({\"input\": \"ç”Ÿæˆä¸€å¼ ç¤ºä¾‹å°å›¾\"})\n",
    "        print(f\"ğŸ¤– Agent: {response['output']}\")\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "await run_image_agent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2215e8f7",
   "metadata": {},
   "source": [
    "## ğŸ”„ ç¬¬ 3 éƒ¨åˆ†ï¼šé•¿æ—¶é—´è¿è¡Œçš„æ“ä½œ (äººæœºäº¤äº’)\n",
    "\n",
    "è¿™éƒ¨åˆ†å†…å®¹ä¸ä¹‹å‰ç›¸åŒï¼Œæˆ‘ä»¬ä½¿ç”¨ LangChain æœ¬åœ°å·¥å…·æ¨¡æ‹Ÿå®¡æ‰¹æµã€‚\n",
    "\n",
    "æ³¨æ„ï¼šç”±äºæˆ‘ä»¬ç°åœ¨åœ¨ async ç¯å¢ƒä¸­è¿è¡Œï¼ˆä¸ºäº†æ”¯æŒ MCPï¼‰ï¼Œæˆ‘ä»¬çš„å·¥å…·ä¹Ÿå¯ä»¥æ˜¯ async çš„ï¼Œæˆ–è€…ç›´æ¥ä½¿ç”¨ input() é˜»å¡ï¼ˆåœ¨æœ¬åœ° Demo ä¸­é€šå¸¸æ²¡é—®é¢˜ï¼‰ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def place_shipping_order(num_containers: int, destination: str) -> str:\n",
    "    \"\"\"\n",
    "    å¤„ç†å‘è´§è®¢å•ã€‚å¦‚æœé›†è£…ç®±æ•°é‡ > 5ï¼Œå°†è§¦å‘äººå·¥å®¡æ‰¹æµç¨‹ã€‚\n",
    "    \"\"\"\n",
    "    LARGE_ORDER_THRESHOLD = 5\n",
    "    \n",
    "    print(f\"    ğŸš¢ [å·¥å…·] æ­£åœ¨å¤„ç†è®¢å•: {num_containers} ä¸ªé›†è£…ç®± -> {destination}...\")\n",
    "    \n",
    "    if num_containers <= LARGE_ORDER_THRESHOLD:\n",
    "        order_id = f\"ORD-{num_containers}-AUTO\"\n",
    "        return f\"âœ… è‡ªåŠ¨æ‰¹å‡†: {num_containers} ä¸ªé›†è£…ç®±å·²å‘å¾€ {destination}ã€‚è®¢å•å·: {order_id}\"\n",
    "    \n",
    "    print(f\"\\n    âš ï¸  æ£€æµ‹åˆ°å¤§é¢è®¢å• > {LARGE_ORDER_THRESHOLD}\")\n",
    "    print(f\"    â¸ï¸  [ç³»ç»Ÿæš‚åœ] ç­‰å¾…äººå·¥æ‰¹å‡†...\")\n",
    "    \n",
    "    # é˜»å¡å¼è¾“å…¥\n",
    "    user_decision = input(f\"    ğŸ¤” æ‰¹å‡†è¿é€ {num_containers} ä¸ªé›†è£…ç®±åˆ° {destination} å—ï¼Ÿ(è¾“å…¥ yes/no): \").strip().lower()\n",
    "    \n",
    "    if user_decision in ['yes', 'y', 'ok', 'approve', 'æ˜¯', 'å¥½']:\n",
    "        order_id = f\"ORD-{num_containers}-HUMAN\"\n",
    "        print(f\"    âœ… äººå·¥å·²æ‰¹å‡†ã€‚\")\n",
    "        return f\"âœ… äººå·¥å·²æ‰¹å‡†: {num_containers} ä¸ªé›†è£…ç®±å·²å‘å¾€ {destination}ã€‚è®¢å•å·: {order_id}\"\n",
    "    else:\n",
    "        print(f\"    âŒ äººå·¥å·²æ‹’ç»ã€‚\")\n",
    "        return f\"âŒ äººå·¥å·²æ‹’ç»: è®¢å•å·²å–æ¶ˆã€‚\"\n",
    "\n",
    "print(\"âœ… å·¥å…· `place_shipping_order` å·²å°±ç»ªã€‚\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç‰©æµ Agent\n",
    "shipping_tools = [place_shipping_order]\n",
    "\n",
    "shipping_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€åç‰©æµåè°ƒå‘˜ã€‚ä½¿ç”¨å·¥å…·å¤„ç†è®¢å•ã€‚\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "llm = ChatOpenAI(model=config[\"model_name\"], temperature=0)\n",
    "shipping_agent = create_tool_calling_agent(llm, shipping_tools, shipping_prompt)\n",
    "shipping_runner = AgentExecutor(agent=shipping_agent, tools=shipping_tools, verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "# æ¼”ç¤º\n",
    "print(\"--- æ¼”ç¤º: å¤§é¢è®¢å• ---\")\n",
    "print(\"(ç³»ç»Ÿå°†æç¤ºä½ è¾“å…¥...)\")\n",
    "await shipping_runner.ainvoke({\"input\": \"è¿é€ 3 ä¸ªé›†è£…ç®±åˆ°æ–°åŠ å¡\"})\n",
    "await shipping_runner.ainvoke({\"input\": \"è¿é€ 10 ä¸ªé›†è£…ç®±åˆ°é¹¿ç‰¹ä¸¹\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458b0ae",
   "metadata": {},
   "source": [
    "## ğŸ“Š æ€»ç»“\n",
    "\n",
    "æˆ‘ä»¬æˆåŠŸåœ°ï¼š\n",
    "1. **è¿æ¥äº†çœŸå®çš„ MCP æœåŠ¡å™¨**: ä½¿ç”¨ `npx` å¯åŠ¨å¹¶é€šè¿‡ `mcp` SDK é€šä¿¡ã€‚\n",
    "2. **é›†æˆäº† LangChain**: ç¼–å†™äº†é€‚é…å™¨å°† MCP å·¥å…·åŠ¨æ€è½¬æ¢ä¸º LangChain å·¥å…·ã€‚\n",
    "3. **ä¿æŒäº†äº¤äº’æ€§**: å®ç°äº† Human-in-the-Loop ç”¨äºæ•æ„Ÿæ“ä½œã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (5-DAY-AGENT)",
   "language": "python",
   "name": "5-day-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
