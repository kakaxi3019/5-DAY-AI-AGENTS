# Day 4b - Agent 评估 (Evaluation) - [已跳过]

## 📖 1. 原课程内容简介

在 5-Day Agent Course 的这一章节 (Day 4b) 中，课程重点从 **被动调试 (Observability)** 转向了 **主动评估 (Evaluation)**。

核心目标是建立一套系统化的流程，用于检测 Agent 的性能稳定性。主要涵盖：
*   **创建有缺陷的 Agent**: 构建一个“过度自信”的智能家居助手，用于模拟现实中的错误场景。
*   **构建测试集**: 在 Web UI 中通过交互，从用户的真实对话中提取并保存“输入-输出”对作为测试标准。
*   **回归测试**: 使用命令行工具批量运行测试用例，检测 Agent 在代码变更后是否保持了原有的能力。

## ⚠️ 2. 为什么本项目不复刻此章节

原 Kaggle 课程在这一节的教学核心高度绑定了 **Google ADK (Agent Development Kit)** 的生态工具链：

1.  **ADK Web UI**: 提供了一个完整的全栈可视化界面，核心教学点在于通过 UI 交互来创建、管理测试用例。
2.  **闭源工具链**: 依赖 `adk eval` 命令行工具以及深度集成的 `pytest` 插件来进行自动化的批量回归测试。

**不复刻的原因**：
要在本地环境复刻这一套体验（特别是 Web UI 部分），相当于需要开发一个完整的 Agent 测试平台（包含前端、后端及数据库）。而在没有图形界面的情况下纯用代码模拟，不仅实现难度大，而且丢失了原课程“可视化评估”的核心体验价值。

因此，作者决定目前 **不复刻** 这一节内容。

## 📚 3. 学习建议

如果您对 Google ADK 提供的这套的可视化评估工作流感兴趣，或者希望在此基础上进行产品化开发。

👉 **推荐直接前往 Google 官方教程进行学习：**

*   **[Google AI Agents Course (Kaggle)](https://www.kaggle.com/code/kaggle5daysofai/day-4b-agent-evaluation)**

