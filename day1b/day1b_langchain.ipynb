{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bcf796b",
   "metadata": {},
   "source": [
    "\n",
    "# Day 1b: Agent Architecturesï¼ˆLangChainå¯æœ¬åœ°è¿è¡Œç‰ˆï¼‰\n",
    "\n",
    "## ğŸš€ ç¬¬ä¸€å¤©ï¼ˆbï¼‰- ä»£ç†æ¶æ„\n",
    "\n",
    "æ¬¢è¿æ¥åˆ° 5 å¤© Agent è¯¾ç¨‹çš„ Day 1bï¼\n",
    "\n",
    "åœ¨ Day 1a ä¸­ï¼Œä½ æ„å»ºäº†ä¸€ä¸ªèƒ½å¤Ÿä½¿ç”¨å·¥å…·çš„å•ä¸€ Agentã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†å‡çº§åˆ°**å¤š Agent ç³»ç»Ÿ**ã€‚\n",
    "\n",
    "å°±åƒç°å®ä¸–ç•Œä¸­çš„å›¢é˜Ÿä¸€æ ·ï¼Œä½ å¯ä»¥åˆ›å»ºä¸€ç»„**ä¸“ä¸šåŒ–**çš„ Agentï¼Œå®ƒä»¬åä½œè§£å†³å¤æ‚é—®é¢˜ã€‚è¿™æ˜¯ AI Agent å¼€å‘ä¸­æœ€å¼ºå¤§çš„æ¦‚å¿µä¹‹ä¸€ã€‚\n",
    "\n",
    "åœ¨æœ¬ Notebook ä¸­ï¼Œä½ å°†ï¼š\n",
    "\n",
    "- âœ… **äº†è§£ä½•æ—¶ä½¿ç”¨å¤š Agent ç³»ç»Ÿ**\n",
    "- âœ… **æ„å»ºä½ çš„ç¬¬ä¸€ä¸ªå¤š Agent ç³»ç»Ÿ** (ä½¿ç”¨ LLM ä½œä¸º\"ç»ç†\")\n",
    "- âœ… **æŒæ¡ä¸‰ç§æ ¸å¿ƒå·¥ä½œæµæ¨¡å¼**ï¼š\n",
    "    1. **é¡ºåºæ¨¡å¼ (Sequential)**: åƒæµæ°´çº¿ä¸€æ ·ä¸€æ­¥æ­¥æ‰§è¡Œ\n",
    "    2. **å¹¶è¡Œæ¨¡å¼ (Parallel)**: åŒæ—¶æ‰§è¡Œå¤šä¸ªä»»åŠ¡ä»¥æé«˜æ•ˆç‡\n",
    "    3. **å¾ªç¯æ¨¡å¼ (Loop)**: é€šè¿‡åå¤ä¿®æ­£æ¥æé«˜è´¨é‡\n",
    "\n",
    "---\n",
    "\n",
    "**åŸç‰ˆ**: Google ADK Team (Kaggle 5-Day Agent Course)  \n",
    "**æ”¹å†™**: LangChain å®ç°\n",
    "> **â„¹ï¸ å£°æ˜**: æœ¬æ•™ç¨‹æ”¹ç¼–è‡ª Google [5-Day AI Agents Course](https://www.kaggle.com/learn-guide/5-day-agents)ï¼Œç”± LangChain é‡å†™ä»¥é€‚é…æœ¬åœ°è¿è¡Œã€‚å†…å®¹ä»…ä¾›å­¦ä¹ ç ”ç©¶ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e65ce",
   "metadata": {},
   "source": [
    "\n",
    "## âš™ï¸ Section 1: Setup (ç¯å¢ƒè®¾ç½®)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c199fdc",
   "metadata": {},
   "source": [
    "### 1.1 åˆ‡æ¢å†…æ ¸\n",
    "- ç‚¹å‡»å³ä¸Šè§’çš„ Kernel (å†…æ ¸) é€‰æ‹©åŒºåŸŸã€‚\n",
    "- åœ¨åˆ—è¡¨ä¸­é€‰æ‹© Python (5-DAY-AGENTS)ã€‚\n",
    "\n",
    "> å…³äºå¦‚ä½•åˆå§‹åŒ–ç¯å¢ƒå’Œåˆ›å»ºå†…æ ¸ï¼Œè¯·æŸ¥çœ‹ [README å¦‚ä½•è¿è¡Œ](../README.md#-å¦‚ä½•è¿è¡Œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7ea0af",
   "metadata": {},
   "source": [
    "### 1.2 å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¼˜é€‰ uv åŒ…ç®¡ç†å™¨ \n",
    "!uv pip install langchain langchain-openai langchain-community python-dotenv duckduckgo-search tavily-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80141c3b",
   "metadata": {},
   "source": [
    "### 1.3 å¯¼å…¥ä¾èµ–åº“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cb3358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# LangChain æ ¸å¿ƒç»„ä»¶\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "\n",
    "# æœç´¢å·¥å…·\n",
    "from langchain_community.tools import DuckDuckGoSearchResults, TavilySearchResults\n",
    "\n",
    "# å¿½ç•¥è­¦å‘Š\n",
    "from langchain_core._api.deprecation import LangChainDeprecationWarning\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)\n",
    "\n",
    "print(\"âœ… ä¾èµ–åº“å¯¼å…¥æˆåŠŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f8943",
   "metadata": {},
   "source": [
    "### 1.4 é…ç½® API Key\n",
    "\n",
    "> å…³äº .env æ–‡ä»¶å†…å®¹è¯´æ˜ï¼Œè¯·æŸ¥çœ‹ [README ç¯å¢ƒé…ç½®æ–‡ä»¶ (.env) è¯´æ˜](../README.md#3-ç¯å¢ƒé…ç½®æ–‡ä»¶-env-è¯´æ˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3187ee26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ç¯å¢ƒå˜é‡\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "def configure_api_keys():\n",
    "    \"\"\"åŠ è½½å¹¶éªŒè¯ API é…ç½®\"\"\"\n",
    "    model_name = os.environ.get(\"MODEL_NAME\")\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "    base_url = os.environ.get(\"OPENAI_API_BASE\")\n",
    "    tavily_key = os.environ.get(\"TAVILY_API_KEY\")\n",
    "\n",
    "    if not api_key:\n",
    "        print(\"âŒ é”™è¯¯: æœªåœ¨ .env æ–‡ä»¶ä¸­æ‰¾åˆ° OPENAI_API_KEY\")\n",
    "        return None\n",
    "    \n",
    "    # æ‰“å°éƒ¨åˆ† Key ä»¥éªŒè¯ (éšè—æ•æ„Ÿä¿¡æ¯)\n",
    "    masked_key = f\"{api_key[:8]}...\" if api_key else \"None\"\n",
    "    print(f\"âœ… API Key å·²åŠ è½½: {masked_key}\")\n",
    "    print(f\"âœ… ä½¿ç”¨æ¨¡å‹: {model_name}\")\n",
    "    if base_url:\n",
    "        print(f\"âœ… API Base URL: {base_url}\")\n",
    "    \n",
    "    if tavily_key:\n",
    "        print(\"âœ… Tavily Search API å·²å¯ç”¨ (å¢å¼ºæœç´¢èƒ½åŠ›)\")\n",
    "    else:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ° Tavily Keyï¼Œå°†ä½¿ç”¨ DuckDuckGo æœç´¢ (å…è´¹ä½†è´¨é‡å¯èƒ½å—é™)\")\n",
    "    \n",
    "    return {\n",
    "        \"model_name\": model_name,\n",
    "        \"api_key\": api_key,\n",
    "        \"base_url\": base_url,\n",
    "        \"tavily_key\": tavily_key,\n",
    "        \"extra_body\": json.loads(os.environ.get(\"EXTRA_BODY\", \"{}\"))\n",
    "    }\n",
    "\n",
    "config = configure_api_keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a81355",
   "metadata": {},
   "source": [
    "### 1.5 åˆå§‹åŒ– LLM\n",
    "\n",
    "ç°åœ¨ï¼Œè®©æˆ‘ä»¬åˆå§‹åŒ– LangChain çš„ ChatOpenAI æ¨¡å‹ã€‚è¿™ç›¸å½“äº ADK ä¸­çš„ `Gemini` æ¨¡å‹é…ç½®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c799e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆå§‹åŒ– LLM\n",
    "llm = ChatOpenAI(\n",
    "    model=config[\"model_name\"],\n",
    "    api_key=config[\"api_key\"],\n",
    "    base_url=config[\"base_url\"],\n",
    "    temperature=0.7,\n",
    "    extra_body=config[\"extra_body\"]\n",
    ")\n",
    "\n",
    "print(\"âœ… LLM åˆå§‹åŒ–å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b2acf",
   "metadata": {},
   "source": [
    "\n",
    "### 1.6 å®šä¹‰é€šç”¨å·¥å…·\n",
    "\n",
    "æˆ‘ä»¬å°†ç»§ç»­ä½¿ç”¨ Day 1a ä¸­çš„ç½‘ç»œæœç´¢å·¥å…·ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881b602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tool\n",
    "def internet_search(query: str) -> str:\n",
    "    '''\n",
    "    Performs an internet search using Tavily (preferred) or DuckDuckGo (fallback).\n",
    "    Use this tool to find answer about current events, weather, or specific facts.\n",
    "    '''\n",
    "    if config[\"tavily_key\"]:\n",
    "        try:\n",
    "            # print(f\"    ğŸ” [Search] Tavily: '{query}'\")\n",
    "            return TavilySearchResults(k=3).run(query)\n",
    "        except Exception:\n",
    "            pass\n",
    "    \n",
    "    # print(f\"    ğŸ” [Search] DuckDuckGo: '{query}'\")\n",
    "    return DuckDuckGoSearchResults(backend=\"api\").run(query)\n",
    "\n",
    "print(\"âœ… å·¥å…· internet_search å·²å‡†å¤‡å°±ç»ª\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42568c22",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ¤” Section 2: ä¸ºä»€ä¹ˆè¦ä½¿ç”¨å¤š Agent ç³»ç»Ÿï¼Ÿ\n",
    "\n",
    "**é—®é¢˜ï¼š** å•ä¸ª \"å…¨èƒ½\" Agent å¾€å¾€ä¼šé¡¾æ­¤å¤±å½¼ã€‚å¦‚æœè®©ä¸€ä¸ª Agent åŒæ—¶è´Ÿè´£ç ”ç©¶ã€å†™ä½œã€ç¼–è¾‘å’Œæ ¸æŸ¥ï¼Œå®ƒçš„ Prompt ä¼šå˜å¾—éå¸¸é•¿ä¸”éš¾ä»¥ç»´æŠ¤ï¼Œä¸”å®¹æ˜“å‡ºé”™ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆï¼š** **ä¸“å®¶å›¢é˜Ÿ**ã€‚\n",
    "æˆ‘ä»¬å°†ä»»åŠ¡åˆ†è§£ç»™å¤šä¸ªè§’è‰²å•ä¸€çš„ Agentï¼ˆä¾‹å¦‚ï¼Œä¸€ä¸ªåªè´Ÿè´£æœç´¢ï¼Œå¦ä¸€ä¸ªåªè´Ÿè´£æ€»ç»“ï¼‰ã€‚\n",
    "\n",
    "### 2.1 ç¤ºä¾‹ï¼šç ”ç©¶ä¸æ€»ç»“ç³»ç»Ÿ (Coordinator æ¨¡å¼)\n",
    "\n",
    "æˆ‘ä»¬æ„å»ºä¸€ä¸ªç³»ç»Ÿï¼ŒåŒ…å«ï¼š\n",
    "1. **ç ”ç©¶å‘˜ (Research Agent)**: ä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾ä¿¡æ¯ã€‚\n",
    "2. **æ€»ç»“å‘˜ (Summarizer Agent)**: å°†æŸ¥æ‰¾çš„ä¿¡æ¯æ•´ç†æˆæ‘˜è¦ã€‚\n",
    "3. **åè°ƒå‘˜ (Coordinator/Root Agent)**: è´Ÿè´£æŒ‡æŒ¥å‰ä¸¤ä¸ª Agent å·¥ä½œã€‚\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å°† \"å­ Agent\" å°è£…ä¸º **Tool** ä¾› \"æ ¹ Agent\" è°ƒç”¨ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbaec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 1. å®šä¹‰ ç ”ç©¶å‘˜ (Research Agent) ---\n",
    "# å®ƒæ˜¯ä¸€ä¸ªå¯ä»¥è¯´ \"æŸ¥æ‰¾å…³äº X çš„ä¿¡æ¯\" çš„ Agent\n",
    "research_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç ”ç©¶å‘˜ã€‚ä½ çš„ä»»åŠ¡æ˜¯ä½¿ç”¨æœç´¢å·¥å…·æŸ¥æ‰¾å…³äºç”¨æˆ·ç»™å®šä¸»é¢˜çš„è¯¦ç»†ä¿¡æ¯ã€‚è¯·æŸ¥æ‰¾ 2-3 ä¸ªå…³é”®ç‚¹å¹¶æä¾›æ¥æºã€‚\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "research_agent = create_tool_calling_agent(llm, [internet_search], research_prompt)\n",
    "research_executor = AgentExecutor(agent=research_agent, tools=[internet_search], verbose=False)\n",
    "\n",
    "# å°†å…¶å°è£…ä¸ºå·¥å…·ä¾› Coordinator ä½¿ç”¨\n",
    "@tool\n",
    "def research_tool(topic: str) -> str:\n",
    "    '''ç”¨äºç ”ç©¶ç‰¹å®šä¸»é¢˜çš„å·¥å…·ã€‚è¾“å…¥åº”è¯¥æ˜¯ä»ç”¨æˆ·é—®é¢˜ä¸­æå–çš„ç ”ç©¶ä¸»é¢˜ã€‚'''\n",
    "    print(f\"  ğŸ¤– [ResearchAgent] æ­£åœ¨ç ”ç©¶: {topic}...\")\n",
    "    result = research_executor.invoke({\"input\": topic})\n",
    "    return result[\"output\"]\n",
    "\n",
    "print(\"âœ… research_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. å®šä¹‰ æ€»ç»“å‘˜ (Summarizer Agent) ---\n",
    "# å®ƒåªéœ€è¦å¤„ç†æ–‡æœ¬ï¼Œä¸éœ€è¦å¤–éƒ¨å·¥å…·ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç”¨ç®€å•çš„ Chain\n",
    "summarizer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"é˜…è¯»ä»¥ä¸‹ç ”ç©¶èµ„æ–™:\\n\\n{research_findings}\\n\\nè¯·å°†å…¶æ€»ç»“ä¸ºä¸€ä¸ªåŒ…å« 3-5 ä¸ªè¦ç‚¹çš„åˆ—è¡¨ï¼Œè¯­è¨€ç®€æ´æ˜äº†ã€‚\"\n",
    ")\n",
    "# ä½¿ç”¨ LCEL: Prompt -> LLM -> OutputParser\n",
    "summarizer_chain = summarizer_prompt | llm | StrOutputParser()\n",
    "\n",
    "@tool\n",
    "def summarizer_tool(content: str) -> str:\n",
    "    '''ç”¨äºæ€»ç»“æ–‡æœ¬çš„å·¥å…·ã€‚è¾“å…¥åº”è¯¥æ˜¯éœ€è¦æ€»ç»“çš„é•¿æ–‡æœ¬ã€‚'''\n",
    "    print(f\"  ğŸ“ [SummarizerAgent] æ­£åœ¨æ€»ç»“...\")\n",
    "    return summarizer_chain.invoke({\"research_findings\": content})\n",
    "\n",
    "print(\"âœ… summarizer_agent created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6212180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. å®šä¹‰ åè°ƒå‘˜ (Root/Coordinator Agent) ---\n",
    "coordinator_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", '''ä½ æ˜¯ä¸€åç ”ç©¶åè°ƒå‘˜ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡é€šè¿‡åè°ƒå­ Agent æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n",
    "    \n",
    "    è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š\n",
    "    1. è°ƒç”¨ `research_tool` æŸ¥æ‰¾ç›¸å…³ä¿¡æ¯ã€‚\n",
    "    2. è·å–ç ”ç©¶ç»“æœåï¼Œè°ƒç”¨ `summarizer_tool` è¿›è¡Œæ€»ç»“ã€‚\n",
    "    3. æœ€åï¼Œå°†æ€»ç»“ç»“æœå±•ç¤ºç»™ç”¨æˆ·ã€‚'''),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "root_tools = [research_tool, summarizer_tool]\n",
    "coordinator_agent = create_tool_calling_agent(llm, root_tools, coordinator_prompt)\n",
    "coordinator_runner = AgentExecutor(agent=coordinator_agent, tools=root_tools, verbose=True, handle_parsing_errors=True) # Verbose True ä»¥ä¾¿çœ‹åˆ°è°ƒç”¨è¿‡ç¨‹\n",
    "\n",
    "print(\"âœ… å¤š Agent ç³»ç»Ÿ (Coordinator æ¨¡å¼) åˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f59cc",
   "metadata": {},
   "source": [
    "\n",
    "### è¿è¡Œ Coordinator Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96eecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"é‡å­è®¡ç®—çš„æœ€æ–°è¿›å±•åŠå…¶å¯¹ AI çš„æ„ä¹‰\"\n",
    "print(f\"User > {query}\\n\")\n",
    "\n",
    "response = coordinator_runner.invoke({\"input\": query})\n",
    "print(f\"\\nRootAgent > {response['output']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cece546",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸš¥ Section 3: é¡ºåºå·¥ä½œæµ (Sequential Workflows) - æµæ°´çº¿\n",
    "\n",
    "**é—®é¢˜ï¼š** ä»…ä»…ä¾é  LLM \"å†³å®š\" è°ƒç”¨è°ï¼ˆå¦‚ä¸Šé¢çš„ Coordinatorï¼‰æœ‰æ—¶ä¼šä¸ç¨³å®šã€‚å¦‚æœ LLM å†³å®šè·³è¿‡ä¸€æ­¥æ€ä¹ˆåŠï¼Ÿ\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆï¼š** **å›ºå®šæµæ°´çº¿ (Sequential/Chain)**ã€‚\n",
    "å½“ä»»åŠ¡é¡ºåºå›ºå®šï¼ˆA -> B -> Cï¼‰æ—¶ï¼Œæˆ‘ä»¬å¯ä»¥å¼ºåˆ¶å®šä¹‰æ‰§è¡Œé¡ºåºã€‚\n",
    "\n",
    "### 3.1 ç¤ºä¾‹ï¼šåšå®¢åˆ›ä½œæµæ°´çº¿\n",
    "\n",
    "æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªåŒ…å«ä¸‰ä¸ªç¯èŠ‚çš„æµæ°´çº¿ï¼š\n",
    "1. **å¤§çº² (Outline)**: ç”Ÿæˆåšå®¢å¤§çº²\n",
    "2. **å†™ä½œ (Write)**: æ ¹æ®å¤§çº²å†™è‰ç¨¿\n",
    "3. **ç¼–è¾‘ (Edit)**: æ¶¦è‰²è‰ç¨¿\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œè¿™æ˜¯æœ€ç»å…¸çš„ **LCEL Chain** (`|` è¿ç®—ç¬¦)ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9250d150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. å¤§çº²ç”Ÿæˆå™¨\n",
    "outline_prompt = ChatPromptTemplate.from_template(\n",
    "    \"æ—¢ç„¶ä½ æ˜¯ OutlineAgentã€‚è¯·ä¸ºä¸»é¢˜ '{topic}' åˆ›å»ºä¸€ä¸ªåšå®¢å¤§çº²ï¼ŒåŒ…å«å¼•äººå…¥èƒœçš„æ ‡é¢˜ã€ä»‹ç»ã€3-5ä¸ªä¸»è¦æ®µè½è¦ç‚¹å’Œç»“è®ºã€‚\"\n",
    ")\n",
    "outline_chain = outline_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 2. æ’°å†™å·¥\n",
    "writer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"æ—¢ç„¶ä½ æ˜¯ WriterAgentã€‚è¯·æ ¹æ®ä»¥ä¸‹å¤§çº²æ’°å†™ä¸€ç¯‡ 200-300 å­—çš„åšå®¢æ–‡ç« ï¼Œè¯­æ°”è¦ç”ŸåŠ¨æœ‰è¶£ã€‚\\n\\nå¤§çº²:\\n{outline}\"\n",
    ")\n",
    "writer_chain = writer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 3. ç¼–è¾‘\n",
    "editor_prompt = ChatPromptTemplate.from_template(\n",
    "    \"æ—¢ç„¶ä½ æ˜¯ EditorAgentã€‚è¯·ç¼–è¾‘ä»¥ä¸‹è‰ç¨¿ï¼Œä¿®æ­£è¯­æ³•é”™è¯¯ï¼Œä¼˜åŒ–æµç•…åº¦ï¼Œå¹¶ä½¿å…¶æ›´åŠ æ¸…æ™°ã€‚\\n\\nè‰ç¨¿:\\n{draft}\"\n",
    ")\n",
    "editor_chain = editor_prompt | llm | StrOutputParser()\n",
    "\n",
    "# --- æ„å»ºé¡ºåºé“¾ (Sequential Chain) ---\n",
    "# é€»è¾‘: Unput(Topic) -> Outline -> Writer -> Editor -> Final Output\n",
    "# æˆ‘ä»¬ä½¿ç”¨ RunnablePassthrough æ¥ä¼ é€’ä¸­é—´å˜é‡\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# å®šä¹‰å®Œæ•´çš„æµæ°´çº¿\n",
    "# æ­¥éª¤ 1: ç”Ÿæˆå¤§çº²\n",
    "chain_step1 = {\"outline\": outline_chain} \n",
    "\n",
    "# æ­¥éª¤ 2: ç”Ÿæˆè‰ç¨¿ (è¾“å…¥æ˜¯ä¸Šä¸€æ­¥çš„å­—å…¸ï¼ŒåŒ…å« outline)\n",
    "chain_step2 = {\"draft\": writer_chain}\n",
    "\n",
    "# æ­¥éª¤ 3: ç¼–è¾‘è‰ç¨¿ (è¾“å…¥æ˜¯ä¸Šä¸€æ­¥çš„å­—å…¸ï¼ŒåŒ…å« draft)\n",
    "chain_step3 = editor_chain\n",
    "\n",
    "# è¿æ¥èµ·æ¥\n",
    "# æ³¨æ„: ä¸ºäº†è®©æ¯ä¸€æ­¥éƒ½èƒ½æ‹¿åˆ°å®ƒéœ€è¦çš„è¾“å…¥å˜é‡ï¼Œæˆ‘ä»¬éœ€è¦å·§å¦™åœ°ç»„åˆ Runnables\n",
    "# æ›´ç®€å•çš„æ–¹æ³•æ˜¯æ˜¾å¼åœ°ä¼ é€’æ•°æ®æµ\n",
    "\n",
    "def run_blog_pipeline(topic):\n",
    "    print(f\"ğŸ“ [OutlineAgent] æ­£åœ¨ç”Ÿæˆå¤§çº²: '{topic}'...\")\n",
    "    outline = outline_chain.invoke({\"topic\": topic})\n",
    "    print(f\"\\n--- å¤§çº² ---\\n{outline[:100]}...\\n\")\n",
    "    \n",
    "    print(f\"âœï¸ [WriterAgent] æ­£åœ¨æ’°å†™è‰ç¨¿...\")\n",
    "    draft = writer_chain.invoke({\"outline\": outline})\n",
    "    print(f\"\\n--- åˆç¨¿ ---\\n{draft[:100]}...\\n\")\n",
    "    \n",
    "    print(f\"ğŸ” [EditorAgent] æ­£åœ¨æ¶¦è‰²...\")\n",
    "    final_post = editor_chain.invoke({\"draft\": draft})\n",
    "    \n",
    "    return final_post\n",
    "\n",
    "print(\"âœ… åšå®¢åˆ›ä½œæµæ°´çº¿å·²å°±ç»ª (Function-based sequential workflow)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# è¿è¡Œæµæ°´çº¿\n",
    "topic = \"ä¸ºè½¯ä»¶å¼€å‘äººå‘˜ä»‹ç»å¤š Agent ç³»ç»Ÿçš„ä¼˜åŠ¿\"\n",
    "final_article = run_blog_pipeline(topic)\n",
    "\n",
    "print(f\"\\nğŸš€ [Final Output] æœ€ç»ˆæˆæ–‡:\\n\\n{final_article}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb929e75",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ›£ï¸ Section 4: å¹¶è¡Œå·¥ä½œæµ (Parallel Workflows)\n",
    "\n",
    "**é—®é¢˜ï¼š** é¡ºåºæ‰§è¡Œè™½ç„¶ç¨³å®šï¼Œä½†å¦‚æœä»»åŠ¡ä¹‹é—´æ²¡æœ‰ä¾èµ–å…³ç³»ï¼ˆä¾‹å¦‚ç ”ç©¶ä¸‰ä¸ªä¸åŒçš„ç‹¬ç«‹ä¸»é¢˜ï¼‰ï¼Œé¡ºåºæ‰§è¡Œå¤ªæ…¢äº†ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆï¼š** **å¹¶è¡Œæ‰§è¡Œ (Parallel/Concurrent)**ã€‚\n",
    "åŒæ—¶è¿è¡Œå¤šä¸ª Agentï¼Œæœ€åèšåˆç»“æœã€‚\n",
    "\n",
    "### 4.1 ç¤ºä¾‹ï¼šå¤šä¸»é¢˜ç ”ç©¶ç®€æŠ¥\n",
    "\n",
    "æˆ‘ä»¬å°†åˆ›å»ºä¸‰ä¸ªç ”ç©¶å‘˜å¹¶è¡Œå·¥ä½œï¼Œç„¶åç”±ä¸€ä¸ªèšåˆå‘˜æ±‡æ€»ï¼š\n",
    "1. **Tech Researcher**: ç ”ç©¶ AI è¶‹åŠ¿\n",
    "2. **Health Researcher**: ç ”ç©¶åŒ»ç–—çªç ´\n",
    "3. **Finance Researcher**: ç ”ç©¶é‡‘èç§‘æŠ€\n",
    "4. **Aggregator**: æ±‡æ€»ç®€æŠ¥\n",
    "\n",
    "åœ¨ LangChain ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ `RunnableParallel` æ¥å®ç°å¹¶è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b6332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# å®šä¹‰é€šç”¨çš„ç ”ç©¶ Chain (å¤ç”¨ä¹‹å‰çš„ research agent é€»è¾‘ä¼šæ›´å¤æ‚ï¼Œè¿™é‡Œæˆ‘ä»¬ç”¨ç®€å•çš„ Chain + Tool)\n",
    "# ä¸ºäº†æ¼”ç¤ºå¹¶è¡Œï¼Œæˆ‘ä»¬ç›´æ¥åˆ›å»ºä¸€ä¸ªèƒ½å¤Ÿé€šè¿‡ Search Tool æŸ¥æ‰¾ä¿¡æ¯çš„ Chain\n",
    "\n",
    "def create_research_chain(role_name, focus_area):\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"ä½ æ˜¯ {role_name}ã€‚è¯·ç ”ç©¶ '{focus_area}' çš„æœ€æ–°åŠ¨æ€ã€‚æ‰¾å‡º 3 ä¸ªå…³é”®å‘å±•ã€‚ä¿æŒç®€ç‚¼(100å­—ä»¥å†…)ã€‚\"),\n",
    "        (\"human\", \"{input}\"), # input ä¸»è¦æ˜¯è§¦å‘ triggerï¼Œæˆ–è€…å¯ä»¥ä¸ºç©º\n",
    "        (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "    ])\n",
    "    # è¿™é‡Œæˆ‘ä»¬å¤ç”¨ä¹‹å‰å¸¦æœ‰ search tool çš„ agent ç»“æ„ï¼Œä½†ä¸ºäº†å¹¶è¡Œè¿è¡Œæ–¹ä¾¿ï¼Œå°æˆä¸€ä¸ª Runnable\n",
    "    agent = create_tool_calling_agent(llm, [internet_search], prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=[internet_search], verbose=False)\n",
    "    return executor\n",
    "\n",
    "# åˆ›å»ºä¸‰ä¸ªå¹¶è¡Œ Agent\n",
    "tech_agent = create_research_chain(\"TechResearcher\", \"AI and Machine Learning Trends\")\n",
    "health_agent = create_research_chain(\"HealthResearcher\", \"Medical Breakthroughs and Health News\")\n",
    "finance_agent = create_research_chain(\"FinanceResearcher\", \"Fintech and Economy Trends\")\n",
    "\n",
    "# èšåˆ Agent\n",
    "aggregator_prompt = ChatPromptTemplate.from_template(\n",
    "    '''å°†ä»¥ä¸‹ä¸‰ä¸ªç ”ç©¶æŠ¥å‘Šæ±‡æ€»æˆä¸€ä»½æ‰§è¡Œç®€æŠ¥ï¼š\n",
    "\n",
    "    **Technology:**\n",
    "    {tech_output}\n",
    "\n",
    "    **Health:**\n",
    "    {health_output}\n",
    "\n",
    "    **Finance:**\n",
    "    {finance_output}\n",
    "\n",
    "    è¯·æå–å…±åŒä¸»é¢˜å’Œå…³é”®è¦ç‚¹ã€‚'''\n",
    ")\n",
    "aggregator_chain = aggregator_prompt | llm | StrOutputParser()\n",
    "\n",
    "# æ„å»ºå¹¶è¡Œç»„ä»¶\n",
    "# RunnableParallel ä¼šåŒæ—¶é€šè¿‡ invoke è°ƒç”¨å…¶ä¸­çš„æ¯ä¸ª runnable\n",
    "parallel_research = RunnableParallel({\n",
    "    \"tech_output\": lambda x: tech_agent.invoke({\"input\": \"research latest trends\"})['output'],\n",
    "    \"health_output\": lambda x: health_agent.invoke({\"input\": \"research latest trends\"})['output'],\n",
    "    \"finance_output\": lambda x: finance_agent.invoke({\"input\": \"research latest trends\"})['output'],\n",
    "})\n",
    "\n",
    "# æ„å»ºå®Œæ•´æµç¨‹\n",
    "full_parallel_chain = parallel_research | aggregator_chain\n",
    "\n",
    "print(\"âœ… å¹¶è¡Œç ”ç©¶å·¥ä½œæµå·²æ„å»º\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ğŸš€ å¼€å§‹å¹¶è¡Œç ”ç©¶ (è¿™å¯èƒ½éœ€è¦ä¸€åˆ†é’Ÿï¼Œå› ä¸ºè¦è¿›è¡Œå¤šæ¬¡æœç´¢)...\")\n",
    "final_briefing = full_parallel_chain.invoke(\"Start\") \n",
    "print(f\"\\nğŸ“Š [Executive Briefing] æ¯æ—¥ç®€æŠ¥:\\n\\n{final_briefing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f3550",
   "metadata": {},
   "source": [
    "\n",
    "## â° Section 5: å¾ªç¯å·¥ä½œæµ (Loop Workflows) - åå¤æ‰“ç£¨\n",
    "\n",
    "**é—®é¢˜ï¼š** ä¹‹å‰çš„æ¨¡å¼éƒ½æ˜¯\"ä¸€æ¬¡æ€§\"çš„ (One-Shot)ã€‚ä½†å¾ˆå¤šé«˜è´¨é‡çš„å·¥ä½œéœ€è¦\"å†™-è¯„-æ”¹\"çš„å¾ªç¯ã€‚\n",
    "\n",
    "**è§£å†³æ–¹æ¡ˆï¼š** **å¾ªç¯ä¼˜åŒ– (Iterative Refinement)**ã€‚\n",
    "è®¾ç½®ä¸€ä¸ªå¾ªç¯ï¼šç”Ÿæˆ -> è¯„ä¼° -> (å¦‚æœä¸åˆæ ¼) -> æ”¹è¿› -> å†æ¬¡è¯„ä¼°...\n",
    "\n",
    "### 5.1 ç¤ºä¾‹ï¼šæ•…äº‹åˆ›ä½œä¸æ‰¹è¯„å¾ªç¯\n",
    "\n",
    "1. **Writer**: å†™åˆç¨¿\n",
    "2. **Critic**: æå‡ºä¿®æ”¹æ„è§ï¼Œæˆ–è€…è¯´ \"APPROVED\"\n",
    "3. **Refiner**: æ ¹æ®æ„è§ä¿®æ”¹æ–‡ç« \n",
    "\n",
    "è¿™ä¸ªé€»è¾‘é€šå¸¸ä½¿ç”¨ Python çš„ `while` å¾ªç¯æˆ–è€… `LangGraph` æ¥å®ç°ã€‚è¿™é‡Œæˆ‘ä»¬ç”¨ Python åŸç”Ÿå¾ªç¯æ¼”ç¤ºè¿™ä¸€é€»è¾‘ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49841c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. åˆå§‹ä½œå®¶\n",
    "writer_prompt = ChatPromptTemplate.from_template(\n",
    "    \"è¯·æ ¹æ®ä¸»é¢˜ '{topic}' å†™ä¸€ä¸ªçŸ­ç¯‡æ•…äº‹ï¼ˆ100-150å­—ï¼‰ã€‚åªè¾“å‡ºæ•…äº‹å†…å®¹ã€‚\"\n",
    ")\n",
    "initial_writer = writer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 2. æ‰¹è¯„å®¶\n",
    "critic_prompt = ChatPromptTemplate.from_template(\n",
    "    '''ä½ æ˜¯ä¸€ä¸ªä¸¥å‰çš„æ‰¹è¯„å®¶ã€‚è¯·å®¡é˜…ä¸‹é¢çš„æ•…äº‹ï¼š\n",
    "    \n",
    "    Story: {story}\n",
    "    \n",
    "    å¦‚æœä¸å®Œç¾ï¼Œè¯·ç»™å‡º 2-3 æ¡å…·ä½“çš„ä¿®æ”¹å»ºè®®ã€‚\n",
    "    å¦‚æœæ•…äº‹éå¸¸å‡ºè‰²ä¸”æ— éœ€ä¿®æ”¹ï¼Œè¯·åªå›å¤: APPROVED'''\n",
    ")\n",
    "critic_agent = critic_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 3. æ¶¦è‰²å®¶\n",
    "refiner_prompt = ChatPromptTemplate.from_template(\n",
    "    '''ä½ æ˜¯ä¸€ä¸ªç¼–è¾‘ã€‚è¯·æ ¹æ®æ‰¹è¯„æ„è§é‡å†™æ•…äº‹ã€‚\n",
    "    \n",
    "    åŸæ•…äº‹: {story}\n",
    "    æ‰¹è¯„æ„è§: {critique}\n",
    "    \n",
    "    è¯·è¾“å‡ºä¿®æ”¹åçš„å®Œæ•´æ•…äº‹ã€‚'''\n",
    ")\n",
    "refiner_agent = refiner_prompt | llm | StrOutputParser()\n",
    "\n",
    "# --- å¾ªç¯é€»è¾‘å‡½æ•° ---\n",
    "def run_refinement_loop(topic, max_iterations=3):\n",
    "    print(f\"âœï¸ [Writer] æ­£åœ¨å†™åˆç¨¿: {topic}...\")\n",
    "    current_story = initial_writer.invoke({\"topic\": topic})\n",
    "    print(f\"\\nğŸ“œ [Draft 0]:\\n{current_story}\\n\")\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        print(f\"--- Iteration {i+1} ---\")\n",
    "        \n",
    "        # æ‰¹è¯„\n",
    "        print(f\"ğŸ§ [Critic] æ­£åœ¨å®¡é˜…...\")\n",
    "        critique = critic_agent.invoke({\"story\": current_story})\n",
    "        print(f\"  > æ„è§: {critique}\")\n",
    "        \n",
    "        if \"APPROVED\" in critique:\n",
    "            print(\"\\nâœ… æ•…äº‹å·²è·å¾—æ‰¹å‡†ï¼\")\n",
    "            break\n",
    "            \n",
    "        # æ¶¦è‰²\n",
    "        print(f\"ğŸ”§ [Refiner] æ­£åœ¨æ ¹æ®æ„è§ä¿®æ”¹...\")\n",
    "        current_story = refiner_agent.invoke({\"story\": current_story, \"critique\": critique})\n",
    "        print(f\"\\nğŸ“œ [Draft {i+1}]:\\n{current_story}\\n\")\n",
    "        \n",
    "    return current_story\n",
    "\n",
    "print(\"âœ… å¾ªç¯ä¼˜åŒ–å·¥ä½œæµå·²å®šä¹‰\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74330732",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "topic = \"ä¸€ä¸ªç¯å¡”çœ‹å®ˆäººå‘ç°äº†ä¸€å¼ å‘å…‰çš„ç¥ç§˜åœ°å›¾\"\n",
    "final_story = run_refinement_loop(topic)\n",
    "\n",
    "print(f\"\\nğŸ† [Final Story]:\\n{final_story}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1d9110",
   "metadata": {},
   "source": [
    "\n",
    "## âœ… æ€»ç»“ä¸å›é¡¾\n",
    "\n",
    "æ­å–œï¼ä½ åˆšåˆšæ„å»ºäº†ä¸‰ç§å¼ºå¤§çš„å¤š Agent è®¾è®¡æ¨¡å¼ï¼š\n",
    "\n",
    "| æ¨¡å¼ | é€‚ç”¨åœºæ™¯ | ç¤ºä¾‹ | å…³é”®ç‰¹å¾ |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Coordinator (LLMå†³å®š)** | éœ€è¦åŠ¨æ€å†³ç­– | ç ”ç©¶åè°ƒå‘˜ | LLM å†³å®šè°ƒç”¨å“ªä¸ª Agent/Tool |\n",
    "| **Sequential (æµæ°´çº¿)** | é¡ºåºå›ºå®šçš„ä»»åŠ¡ | åšå®¢åˆ›ä½œ (å¤§çº²->å†™->æ”¹) | ç¡®å®šæ€§çš„ä¸€æ­¥æ¥ä¸€æ­¥ |\n",
    "| **Parallel (å¹¶è¡Œ)** | ç›¸äº’ç‹¬ç«‹çš„ä»»åŠ¡ | å¤šä¸»é¢˜ç ”ç©¶ | åŒæ—¶è¿è¡Œï¼Œé€Ÿåº¦å¿« |\n",
    "| **Loop (å¾ªç¯)** | éœ€è¦è´¨é‡æ‰“ç£¨ | å†™ä½œ+æ‰¹è¯„å¾ªç¯ | åå¤è¿­ä»£ç›´åˆ°æ»¡æ„ |\n",
    "\n",
    "è¿™äº›æ¨¡å¼æ˜¯æ„å»ºå¤æ‚ AI åº”ç”¨çš„åŸºçŸ³ã€‚åœ¨æ¥ä¸‹æ¥çš„è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†æ·±å…¥æ¢è®¨å¦‚ä½•è®©è¿™äº› Agent æ‹¥æœ‰æ›´é•¿æœŸçš„è®°å¿†å’Œæ›´å¤æ‚çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (5-DAY-AGENT)",
   "language": "python",
   "name": "5-day-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
