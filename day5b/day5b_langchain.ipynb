{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Day 5b - Agent Deployment (LangChainå¯æœ¬åœ°è¿è¡Œç‰ˆ)\n",
                "\n",
                "ğŸš€ **å°† Agent éƒ¨ç½²ä¸ºç‹¬ç«‹æœåŠ¡ (LangServe)**\n",
                "\n",
                "æ¬¢è¿æ¥åˆ° Kaggle 5-day Agents è¯¾ç¨‹çš„æœ€åä¸€å¤©ï¼\n",
                "\n",
                "åœ¨ä¹‹å‰çš„è¯¾ç¨‹ä¸­ï¼Œä½ å·²ç»å­¦ä¼šäº†å¦‚ä½•æ„å»ºã€è¯„ä¼°ä»¥åŠè®© Agent äº’ç›¸é€šä¿¡ã€‚ç°åœ¨ï¼Œæˆ‘ä»¬å°†è¿ˆå‡ºæœ€åä¸€æ­¥ï¼š**å°†ä½ çš„ Agent éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ**ã€‚\n",
                "\n",
                "## ğŸ’¡ ä¸ºä»€ä¹ˆè¦éƒ¨ç½²ï¼Ÿ\n",
                "\n",
                "ä½ æ„å»ºäº†ä¸€ä¸ªå¾ˆæ£’çš„ AI Agentï¼Œä½†å®ƒåªå­˜åœ¨äºä½ çš„ Notebook é‡Œã€‚å½“ä½ å…³é—­ Notebook æ—¶ï¼Œå®ƒå°±åœæ­¢å·¥ä½œäº†ã€‚ä½ çš„é˜Ÿå‹æ— æ³•è®¿é—®å®ƒï¼Œç”¨æˆ·ä¹Ÿæ— æ³•ä¸å®ƒäº¤äº’ã€‚\n",
                "\n",
                "éƒ¨ç½²å¯ä»¥å°†ä½ çš„ Agent è½¬åŒ–ä¸ºä¸€ä¸ª**ç‹¬ç«‹è¿è¡Œçš„æœåŠ¡ (Service)**ï¼Œå®ƒå¯ä»¥ï¼š\n",
                "1.  **7x24å°æ—¶è¿è¡Œ**ï¼šéšæ—¶å“åº”è¯·æ±‚ã€‚\n",
                "2.  **è¢«å¤–éƒ¨è®¿é—®**ï¼šå‰ç«¯ç½‘é¡µã€ç§»åŠ¨åº”ç”¨æˆ–å…¶ä»– Agent éƒ½å¯ä»¥è°ƒç”¨å®ƒã€‚\n",
                "3.  **æŒä¹…åŒ–è®°å¿†**ï¼šå³ä½¿ç”¨æˆ·åˆ·æ–°äº†é¡µé¢ï¼Œå¯¹è¯å†å²ä¾ç„¶ä¿ç•™ã€‚\n",
                "\n",
                "## ğŸ”„ LangChain æ”¹å†™è¯´æ˜ï¼šä» Cloud åˆ° Localhost\n",
                "\n",
                "åŸæ•™ç¨‹æ¼”ç¤ºäº†å¦‚ä½•å°† Agent éƒ¨ç½²åˆ° Google Vertex AI Agent Engineã€‚ä¸ºäº†è®©ä½ èƒ½å¤Ÿåœ¨æœ¬åœ°å®Œæ•´ä½“éªŒâ€œæ„å»º-éƒ¨ç½²-è°ƒç”¨â€çš„å…¨æµç¨‹ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **LangServe** æ›¿ä»£äº‘å¹³å°ã€‚\n",
                "\n",
                "| åŠŸèƒ½/æ¦‚å¿µ | åŸæ•™ç¨‹ (Google ADK & Vertex AI) | æœ¬æ•™ç¨‹ (LangChain & LangServe) | è¯´æ˜ |\n",
                "| :--- | :--- | :--- | :--- |\n",
                "| **éƒ¨ç½²ç›®æ ‡** | Vertex AI Agent Engine (äº‘ç«¯å…¨æ‰˜ç®¡) | **LangServe** (æœ¬åœ° FastAPI æœåŠ¡) | è¿™æ˜¯ LangChain å®˜æ–¹æ¨èçš„ç”Ÿäº§çº§éƒ¨ç½²æ–¹æ¡ˆï¼Œæ”¯æŒæµå¼è¾“å‡ºå’Œ API æ–‡æ¡£ã€‚ |\n",
                "| **éƒ¨ç½²å·¥å…·** | `adk deploy` CLI | `uv run server.py` | æˆ‘ä»¬å°†ç¼–å†™ä¸€ä¸ª Python è„šæœ¬æ¥å¯åŠ¨ Web æœåŠ¡å™¨ã€‚ |\n",
                "| **å®¢æˆ·ç«¯ SDK** | `vertexai.agent_engines` | `RemoteRunnable` | LangChain æä¾›çš„å®¢æˆ·ç«¯å·¥å…·ï¼Œå¯ä»¥åƒè°ƒç”¨æœ¬åœ°å‡½æ•°ä¸€æ ·è°ƒç”¨è¿œç¨‹ APIã€‚ |\n",
                "| **é•¿æ—¶è®°å¿†** | Vertex AI Memory Bank | **LangGraph Checkpointer** | ä½¿ç”¨å†…å­˜æˆ–æ•°æ®åº“ (SQLite) ä¿å­˜å¯¹è¯çŠ¶æ€ï¼Œæ¨¡æ‹Ÿâ€œè®°å¿†åº“â€åŠŸèƒ½ã€‚ |\n",
                "\n",
                "## ğŸ¯ æœ¬æ•™ç¨‹å­¦ä¹ ç›®æ ‡\n",
                "\n",
                "âœ… **æ„å»ºç”Ÿäº§å°±ç»ªçš„ Agent**ï¼šä½¿ç”¨ LangGraph å°è£…ä¸šåŠ¡é€»è¾‘ã€‚\n",
                "âœ… **åˆ›å»ºéƒ¨ç½²ä»£ç **ï¼šç¼–å†™ `server.py`ï¼Œä½¿ç”¨ LangServe æš´éœ² APIã€‚\n",
                "âœ… **æœ¬åœ°æ¨¡æ‹Ÿéƒ¨ç½²**ï¼šåœ¨ç»ˆç«¯å¯åŠ¨æœåŠ¡ï¼Œæ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒè¿è¡Œã€‚\n",
                "âœ… **å®¢æˆ·ç«¯æµ‹è¯•**ï¼šä½¿ç”¨ `RemoteRunnable` è¿æ¥å¹¶æµ‹è¯•ä½ çš„ Agentã€‚\n",
                "âœ… **ç†è§£æŒä¹…åŒ–æœºåˆ¶**ï¼šä½“éªŒåŸºäº Session ID çš„çŠ¶æ€ä¿å­˜ã€‚"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âš™ï¸ Section 1: Setup (ç¯å¢ƒè®¾ç½®)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.1 åˆ‡æ¢å†…æ ¸\n",
                "- ç‚¹å‡»å³ä¸Šè§’çš„ Kernel (å†…æ ¸) é€‰æ‹©åŒºåŸŸã€‚\n",
                "- åœ¨åˆ—è¡¨ä¸­é€‰æ‹© Python (5-DAY-AGENTS)ã€‚\n",
                "\n",
                "> å…³äºå¦‚ä½•åˆå§‹åŒ–ç¯å¢ƒå’Œåˆ›å»ºå†…æ ¸ï¼Œè¯·æŸ¥çœ‹ [README å¦‚ä½•è¿è¡Œ](../README.md#å¦‚ä½•è¿è¡Œ)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 1.2 é…ç½® API Key å’Œå¿…è¦çš„åº“ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… API é…ç½®å·²åŠ è½½: Model=Qwen/Qwen3-235B-A22B-Instruct-2507, BaseUrl=https://api-inference.modelscope.cn/v1\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# 1. åŠ è½½ .env æ–‡ä»¶\n",
                "load_dotenv()\n",
                "\n",
                "# 2. é…ç½® API Key\n",
                "def configure_api_keys():\n",
                "    # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨é»˜è®¤å€¼æˆ–ç•™ç©º\n",
                "    model_name = os.getenv(\"MODEL_NAME\", \"gpt-3.5-turbo\")\n",
                "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
                "    openai_api_base = os.getenv(\"OPENAI_API_BASE\")\n",
                "\n",
                "    if not openai_api_key:\n",
                "        raise ValueError(\"âŒ æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·ç¡®ä¿ .env æ–‡ä»¶å·²é…ç½®ã€‚\")\n",
                "\n",
                "    print(f\"âœ… API é…ç½®å·²åŠ è½½: Model={model_name}, BaseUrl={openai_api_base}\")\n",
                "    return model_name, openai_api_key, openai_api_base\n",
                "\n",
                "MODEL_NAME, API_KEY, API_BASE = configure_api_keys()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ—ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šå‡†å¤‡ Agent ä»£ç \n",
                "\n",
                "éƒ¨ç½²çš„ç¬¬ä¸€æ­¥æ˜¯å°†æˆ‘ä»¬çš„ Agent é€»è¾‘ä» Notebook å•å…ƒæ ¼ä¸­æå–å‡ºæ¥ï¼Œæ”¾å…¥ç‹¬ç«‹çš„ Python æ–‡ä»¶ä¸­ã€‚è¿™ç±»ä¼¼äºåŸæ•™ç¨‹ä¸­åˆ›å»º `sample_agent` ç›®å½•çš„æ­¥éª¤ã€‚\n",
                "\n",
                "æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªåä¸º `serving` çš„æ–‡ä»¶å¤¹ï¼Œå¹¶åœ¨å…¶ä¸­åˆ›å»ºä¸¤ä¸ªæ–‡ä»¶ï¼š\n",
                "\n",
                "1.  `agent.py`: å®šä¹‰ Agent çš„æ ¸å¿ƒé€»è¾‘ï¼ˆå·¥å…·ã€æ¨¡å‹ã€å›¾ï¼‰ã€‚\n",
                "2.  `server.py`: å®šä¹‰ Web æœåŠ¡å™¨å…¥å£ï¼Œç”¨äºå¯åŠ¨ API æœåŠ¡ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… ç›®å½• serving/ å·²åˆ›å»º\n"
                    ]
                }
            ],
            "source": [
                "# åˆ›å»ºç›®å½•\n",
                "!mkdir -p serving\n",
                "print(\"âœ… ç›®å½• serving/ å·²åˆ›å»º\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 ç¼–å†™ `agent.py`\n",
                "\n",
                "æˆ‘ä»¬å°†æ„å»ºä¸€ä¸ªç®€å•çš„ **â€œå¤©æ°”åŠ©æ‰‹â€**ã€‚ä¸ºäº†æ¼”ç¤ºç”Ÿäº§çº§ç‰¹æ€§ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ **LangGraph** çš„ `create_react_agent`ï¼Œå› ä¸ºå®ƒå†…ç½®äº†å¯¹ Checkpointerï¼ˆè®°å¿†æŒä¹…åŒ–ï¼‰çš„æ”¯æŒã€‚\n",
                "\n",
                "è¿™ä¸ªæ–‡ä»¶**ä¸è¿è¡Œ**æœåŠ¡ï¼Œåª**å®šä¹‰** Agent å¯¹è±¡ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overwriting serving/agent.py\n"
                    ]
                }
            ],
            "source": [
                "%%writefile serving/agent.py\n",
                "import os\n",
                "from typing import Literal\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.tools import tool\n",
                "from langgraph.prebuilt import create_react_agent\n",
                "from langgraph.checkpoint.memory import MemorySaver\n",
                "\n",
                "# --- 1. å®šä¹‰å·¥å…· ---\n",
                "@tool\n",
                "def get_weather(city: str) -> str:\n",
                "    \"\"\"\n",
                "    æŸ¥è¯¢ç‰¹å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ã€‚\n",
                "    Args:\n",
                "        city: åŸå¸‚åç§° (e.g., \"Tokyo\", \"New York\")\n",
                "    \"\"\"\n",
                "    # æ¨¡æ‹Ÿæ•°æ®\n",
                "    weather_data = {\n",
                "        \"san francisco\": \"San Francisco: æ™´æœ—, 22Â°C\",\n",
                "        \"new york\": \"New York: å¤šäº‘, 18Â°C\",\n",
                "        \"london\": \"London: å°é›¨, 14Â°C\",\n",
                "        \"tokyo\": \"Tokyo: æ™´æœ—, 21Â°C\",\n",
                "        \"paris\": \"Paris: éƒ¨åˆ†å¤šäº‘, 20Â°C\",\n",
                "        \"shanghai\": \"Shanghai: é˜´å¤©, 25Â°C\",\n",
                "        \"beijing\": \"Beijing: æ™´æœ—, 28Â°C\"\n",
                "    }\n",
                "    \n",
                "    city_lower = city.lower()\n",
                "    # ç®€å•çš„æ¨¡ç³ŠåŒ¹é…\n",
                "    for k, v in weather_data.items():\n",
                "        if city_lower in k:\n",
                "            return v\n",
                "            \n",
                "    return f\"æœªæ‰¾åˆ° '{city}' çš„å¤©æ°”ä¿¡æ¯ã€‚\"\n",
                "\n",
                "# --- 2. é…ç½®æ¨¡å‹ ---\n",
                "# æ³¨æ„ï¼šåœ¨ server è¿è¡Œæ—¶ï¼Œç¯å¢ƒå˜é‡éœ€è¦å·²ç»åŠ è½½\n",
                "model = ChatOpenAI(\n",
                "    model=os.environ.get(\"MODEL_NAME\"),\n",
                "    openai_api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
                "    openai_api_base=os.environ.get(\"OPENAI_API_BASE\"),\n",
                "    temperature=0\n",
                ")\n",
                "\n",
                "# --- 3. åˆ›å»º Agent ---\n",
                "# ä½¿ç”¨ MemorySaver æ¥åœ¨å†…å­˜ä¸­ä¿å­˜å¯¹è¯çŠ¶æ€ (Thread)\n",
                "# åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œä½ å¯ä»¥æ›¿æ¢ä¸º PostgresSaver æˆ– SqliteSaver ç­‰æ•°æ®åº“å­˜å‚¨\n",
                "checkpointer = MemorySaver()\n",
                "\n",
                "system_message = \"\"\"\n",
                "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„å¤©æ°”åŠ©æ‰‹ã€‚\n",
                "1. å½“ç”¨æˆ·è¯¢é—®å¤©æ°”æ—¶ï¼Œä½¿ç”¨ get_weather å·¥å…·ã€‚\n",
                "2. å¦‚æœæ‰¾ä¸åˆ°åŸå¸‚ï¼Œå‹å¥½åœ°å‘ŠçŸ¥ç”¨æˆ·ã€‚\n",
                "3. å§‹ç»ˆç”¨ä¸­æ–‡å›ç­”ã€‚\n",
                "\"\"\"\n",
                "\n",
                "# è¿™é‡Œçš„ agent å°±æ˜¯ä¸€ä¸ª CompiledGraph Runnable\n",
                "agent = create_react_agent(\n",
                "    model,\n",
                "    tools=[get_weather],\n",
                "    prompt=system_message,\n",
                "    checkpointer=checkpointer,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 ç¼–å†™ `server.py`\n",
                "\n",
                "ä¸ºäº†å½»åº•è§£å†³ LangServe ä¸ LangGraph Checkpointer ä¹‹é—´çš„å‚æ•°é€ä¼ é—®é¢˜ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨**åŸç”Ÿ FastAPI** æ¥æ„å»ºæœåŠ¡ã€‚\n",
                "\n",
                "è¿™ç§æ–¹å¼è®©æˆ‘ä»¬èƒ½å¤Ÿå®Œå…¨æ§åˆ¶è¯·æ±‚å‚æ•°çš„è§£æï¼Œç¡®ä¿ `thread_id` èƒ½å¤Ÿè¢«æ­£ç¡®åœ°ä¼ é€’ç»™ Agent Runtimeã€‚è¿™ä¹Ÿæ›´æ¥è¿‘ç”Ÿäº§ç¯å¢ƒä¸­å®šåˆ¶åŒ– API çš„åœºæ™¯ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Overwriting serving/server.py\n"
                    ]
                }
            ],
            "source": [
                "%%writefile serving/server.py\n",
                "import os\n",
                "import uvicorn\n",
                "from typing import Any, Dict, List\n",
                "from fastapi import FastAPI, HTTPException\n",
                "from fastapi.middleware.cors import CORSMiddleware\n",
                "from pydantic import BaseModel\n",
                "from dotenv import load_dotenv\n",
                "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
                "\n",
                "# åŠ è½½ç¯å¢ƒå˜é‡ (ç¡®ä¿ API Key å¯ç”¨)\n",
                "load_dotenv()\n",
                "\n",
                "# å¯¼å…¥æˆ‘ä»¬åœ¨ agent.py ä¸­å®šä¹‰çš„ agent\n",
                "from agent import agent\n",
                "\n",
                "# 1. åˆ›å»º FastAPI åº”ç”¨\n",
                "app = FastAPI(\n",
                "    title=\"Weather Assistant API\",\n",
                "    version=\"1.0\",\n",
                "    description=\"A simple Agent API deployed with custom FastAPI endpoints\"\n",
                ")\n",
                "\n",
                "# é…ç½® CORS (å…è®¸è·¨åŸŸè®¿é—®)\n",
                "app.add_middleware(\n",
                "    CORSMiddleware,\n",
                "    allow_origins=[\"*\"],\n",
                "    allow_credentials=True,\n",
                "    allow_methods=[\"*\"],\n",
                "    allow_headers=[\"*\"],\n",
                ")\n",
                "\n",
                "# 2. å®šä¹‰è¯·æ±‚å’Œå“åº”æ¨¡å‹\n",
                "class InvokeRequest(BaseModel):\n",
                "    messages: List[Dict[str, str]]\n",
                "    thread_id: str\n",
                "\n",
                "class InvokeResponse(BaseModel):\n",
                "    messages: List[Dict[str, Any]]\n",
                "\n",
                "# 3. åˆ›å»ºè‡ªå®šä¹‰ç«¯ç‚¹\n",
                "@app.post(\"/weather/invoke\", response_model=InvokeResponse)\n",
                "async def invoke_agent(request: InvokeRequest):\n",
                "    \"\"\"\n",
                "    è°ƒç”¨ Agent å¹¶è¿”å›å“åº”ã€‚\n",
                "    è¿™ä¸ªç«¯ç‚¹å®Œå…¨æ§åˆ¶å¦‚ä½•è°ƒç”¨ LangGraph agentï¼Œç¡®ä¿ config æ­£ç¡®ä¼ é€’ã€‚\n",
                "    \"\"\"\n",
                "    try:\n",
                "        # æ„é€ è¾“å…¥æ¶ˆæ¯\n",
                "        messages = []\n",
                "        for msg in request.messages:\n",
                "            # æ”¯æŒ human/ai å’Œ user/assistant ä¸¤ç§æ ¼å¼\n",
                "            if msg.get(\"type\") == \"human\" or msg.get(\"role\") == \"user\":\n",
                "                messages.append(HumanMessage(content=msg[\"content\"]))\n",
                "            elif msg.get(\"type\") == \"ai\" or msg.get(\"role\") == \"assistant\":\n",
                "                messages.append(AIMessage(content=msg[\"content\"]))\n",
                "        \n",
                "        # æ„é€  configï¼ŒåŒ…å« thread_id\n",
                "        config = {\n",
                "            \"configurable\": {\n",
                "                \"thread_id\": request.thread_id\n",
                "            }\n",
                "        }\n",
                "        \n",
                "        # è°ƒç”¨ agent (LangGraph CompiledGraph)\n",
                "        result = await agent.ainvoke(\n",
                "            {\"messages\": messages},\n",
                "            config=config\n",
                "        )\n",
                "        \n",
                "        # è½¬æ¢å“åº”\n",
                "        response_messages = []\n",
                "        for msg in result[\"messages\"]:\n",
                "            response_messages.append({\n",
                "                \"type\": msg.type if hasattr(msg, \"type\") else \"unknown\",\n",
                "                \"content\": msg.content\n",
                "            })\n",
                "        \n",
                "        return InvokeResponse(messages=response_messages)\n",
                "    \n",
                "    except Exception as e:\n",
                "        raise HTTPException(status_code=500, detail=str(e))\n",
                "\n",
                "@app.get(\"/\")\n",
                "async def root():\n",
                "    return {\n",
                "        \"message\": \"Weather Assistant API\",\n",
                "        \"endpoints\": {\n",
                "            \"invoke\": \"/weather/invoke\",\n",
                "            \"docs\": \"/docs\"\n",
                "        }\n",
                "    }\n",
                "\n",
                "if __name__ == \"__main__\":\n",
                "    # å¯åŠ¨æœåŠ¡ï¼Œç›‘å¬ 8000 ç«¯å£\n",
                "    print(\"ğŸš€ Starting FastAPI Server on http://localhost:8000\")\n",
                "    print(\"ğŸ“ API Documentation: http://localhost:8000/docs\")\n",
                "    uvicorn.run(app, host=\"localhost\", port=8000)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## â˜ï¸ ç¬¬ä¸‰éƒ¨åˆ†ï¼šéƒ¨ç½²ï¼ˆå¯åŠ¨æœåŠ¡ï¼‰\n",
                "\n",
                "åœ¨çœŸå®çš„äº‘éƒ¨ç½²ä¸­ï¼Œä½ ä¼šè¿è¡Œ `adk deploy`ã€‚åœ¨æœ¬åœ°æ¨¡æ‹Ÿä¸­ï¼Œæˆ‘ä»¬éœ€è¦è¿è¡Œ `server.py`ã€‚\n",
                "\n",
                "ğŸ›‘ **é‡è¦è¯´æ˜**ï¼š\n",
                "\n",
                "ç”±äº Web æœåŠ¡å™¨æ˜¯ä¸€ä¸ª**é˜»å¡è¿›ç¨‹**ï¼ˆå®ƒä¼šä¸€ç›´è¿è¡Œç­‰å¾…è¯·æ±‚ï¼‰ï¼Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥åœ¨ Notebook çš„å•å…ƒæ ¼é‡Œè¿è¡Œå®ƒï¼Œå¦åˆ™ Notebook ä¼šå¡ä½ï¼Œæ— æ³•è¿è¡Œåç»­çš„æµ‹è¯•ä»£ç ã€‚\n",
                "\n",
                "**ğŸ‘‰ è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š**\n",
                "\n",
                "1.  **æ‰“å¼€ä¸€ä¸ªæ–°çš„ç»ˆç«¯çª—å£ (Terminal)**ã€‚\n",
                "2.  **è¿›å…¥é¡¹ç›®æ ¹ç›®å½•** (ç¡®ä¿ä½ èƒ½çœ‹åˆ° `.env` æ–‡ä»¶)ã€‚\n",
                "3.  **è¿è¡Œä»¥ä¸‹å‘½ä»¤**å¯åŠ¨æœåŠ¡ï¼š\n",
                "\n",
                "```bash\n",
                "# (æ¨è) ç¡®ä¿åŠ è½½äº†ä¾èµ–ç¯å¢ƒ\n",
                "python serving/server.py \n",
                "# æˆ–è€…æ ¹æ®ä½ çš„ç¯å¢ƒé…ç½®ä½¿ç”¨ uv\n",
                "# uv run python serving/server.py\n",
                "```\n",
                "\n",
                "4.  **ç­‰å¾…å¯åŠ¨**ï¼šç›´åˆ°ä½ çœ‹åˆ°ç»ˆç«¯æ˜¾ç¤º `Starting FastAPI Server` æˆ– `Uvicorn running on http://localhost:8000`ã€‚\n",
                "5.  **å›åˆ°è¿™é‡Œ**ï¼šç»§ç»­è¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼è¿›è¡Œæµ‹è¯•ã€‚\n",
                "\n",
                "*(æ³¨ï¼šå¦‚æœä½ æ— æ³•æ‰“å¼€ç»ˆç«¯ï¼Œä¹Ÿå¯ä»¥å°è¯•åœ¨æµè§ˆå™¨è®¿é—® `http://localhost:8000/docs` æŸ¥çœ‹ API æ–‡æ¡£)*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ¤– ç¬¬å››éƒ¨åˆ†ï¼šå®¢æˆ·ç«¯æµ‹è¯• (ä½¿ç”¨ Python Requests)\n",
                "\n",
                "å› ä¸ºæˆ‘ä»¬è¦æµ‹è¯•ç”Ÿäº§ç¯å¢ƒ APIï¼Œæœ€å¯é çš„æ–¹æ³•æ˜¯ä½¿ç”¨æ ‡å‡†çš„ `requests` åº“æ¥æ¨¡æ‹Ÿå®¢æˆ·ç«¯è°ƒç”¨ã€‚è¿™æ¯” `RemoteRunnable` æ›´é€æ˜ï¼Œæ›´å®¹æ˜“è°ƒè¯•ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import requests\n",
                "import json\n",
                "\n",
                "API_URL = \"http://localhost:8000/weather/invoke\"\n",
                "\n",
                "def chat_with_agent(message: str, thread_id: str):\n",
                "    \"\"\"å‘é€æ¶ˆæ¯åˆ°æœ¬åœ° API å¹¶è·å–å›å¤\"\"\"\n",
                "    payload = {\n",
                "        \"messages\": [\n",
                "            {\"type\": \"human\", \"content\": message}\n",
                "        ],\n",
                "        \"thread_id\": thread_id\n",
                "    }\n",
                "    \n",
                "    try:\n",
                "        response = requests.post(API_URL, json=payload)\n",
                "        response.raise_for_status() # æ£€æŸ¥ 4xx/5xx é”™è¯¯\n",
                "        data = response.json()\n",
                "        \n",
                "        # è·å–æœ€åä¸€æ¡æ¶ˆæ¯ (AI å›å¤)\n",
                "        if data.get(\"messages\"):\n",
                "            last_msg = data[\"messages\"][-1]\n",
                "            print(f\"ğŸ¤– Agent: {last_msg['content']}\")\n",
                "        else:\n",
                "            print(\"âš ï¸ æœªæ”¶åˆ°æœ‰æ•ˆå›å¤\")\n",
                "            \n",
                "    except requests.exceptions.ConnectionError:\n",
                "        print(\"âŒ æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ã€‚è¯·ç¡®ä¿ä½ å·²åœ¨ç»ˆç«¯è¿è¡Œ 'python serving/server.py'\")\n",
                "    except Exception as e:\n",
                "        print(f\"âŒ è¯·æ±‚å¤±è´¥: {e}\")\n",
                "        if 'response' in locals():\n",
                "            print(f\"Server Error Info: {response.text}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 4.1 å‘é€æµ‹è¯•è¯·æ±‚\n",
                "\n",
                "æˆ‘ä»¬æ¥é—®é—®ä¸œäº¬çš„å¤©æ°”ã€‚å¦‚æœä¸€åˆ‡æ­£å¸¸ï¼ŒAPI åº”è¯¥è¿”å›å¤§æ¨¡å‹ç”Ÿæˆçš„å›å¤ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "â³ å‘é€è¯·æ±‚: 'Tokyo çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'...\n",
                        "ğŸ¤– Agent: ä¸œäº¬çš„å¤©æ°”æ™´æœ—ï¼Œæ°”æ¸©ä¸º21Â°Cï¼Œéå¸¸èˆ’é€‚ï¼å¦‚æœå¤–å‡ºè®°å¾—åšå¥½é˜²æ™’å“¦ã€‚\n"
                    ]
                }
            ],
            "source": [
                "print(\"â³ å‘é€è¯·æ±‚: 'Tokyo çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ'...\")\n",
                "chat_with_agent(\"Tokyo çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", thread_id=\"test_thread_003\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ§  ç¬¬äº”éƒ¨åˆ†ï¼šé•¿æ—¶è®°å¿† (Memory Persistence)\n",
                "\n",
                "ç°åœ¨éªŒè¯æœ€é‡è¦çš„åŠŸèƒ½ï¼š**è®°å¿†**ã€‚\n",
                "\n",
                "æˆ‘ä»¬å°†ä½¿ç”¨åŒä¸€ä¸ª `thread_id` è¿›è¡Œä¸¤æ¬¡å¯¹è¯ï¼ŒéªŒè¯ Agent æ˜¯å¦èƒ½è®°ä½ä¸Šä¸‹æ–‡ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "--- æ­¤è½®å¯¹è¯ 1 ---\n",
                        "ğŸ—£ï¸ ç”¨æˆ·: æˆ‘å« Jupiterï¼Œæˆ‘ä½åœ¨ Shanghaiã€‚\n",
                        "ğŸ¤– Agent: ä½ å¥½ï¼ŒJupiterï¼ä¸Šæµ·æ˜¯ä¸ªå¾ˆæ£’çš„åŸå¸‚ã€‚éœ€è¦æˆ‘å¸®ä½ æŸ¥è¯¢ä¸€ä¸‹ä¸Šæµ·çš„å¤©æ°”å—ï¼Ÿ\n"
                    ]
                }
            ],
            "source": [
                "USER_SESSION_ID = \"user_jupiter_session_1\"\n",
                "\n",
                "print(\"\\n--- æ­¤è½®å¯¹è¯ 1 ---\")\n",
                "print(\"ğŸ—£ï¸ ç”¨æˆ·: æˆ‘å« Jupiterï¼Œæˆ‘ä½åœ¨ Shanghaiã€‚\")\n",
                "chat_with_agent(\"æˆ‘å« Jupiterï¼Œæˆ‘ä½åœ¨ Shanghaiã€‚\", thread_id=USER_SESSION_ID)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "... è¿‡äº†å¾ˆä¹… (æ¨¡æ‹Ÿ) ...\n",
                        "\n",
                        "\n",
                        "--- æ­¤è½®å¯¹è¯ 2 ---\n",
                        "ğŸ—£ï¸ ç”¨æˆ·: æˆ‘é‚£é‡Œçš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ (æ²¡æœ‰æåŸå¸‚å)\n",
                        "ğŸ¤– Agent: Jupiterï¼Œä¸Šæµ·ç›®å‰æ˜¯é˜´å¤©ï¼Œæ°”æ¸©ä¸º25Â°Cï¼Œå¤©æ°”æ¯”è¾ƒèˆ’é€‚ã€‚å¦‚æœè¦å‡ºé—¨ï¼Œå¯ä»¥å¸¦ä»¶è–„å¤–å¥—å“¦ï¼\n"
                    ]
                }
            ],
            "source": [
                "print(\"\\n... è¿‡äº†å¾ˆä¹… (æ¨¡æ‹Ÿ) ...\\n\")\n",
                "print(\"\\n--- æ­¤è½®å¯¹è¯ 2 ---\")\n",
                "print(\"ğŸ—£ï¸ ç”¨æˆ·: æˆ‘é‚£é‡Œçš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ (æ²¡æœ‰æåŸå¸‚å)\")\n",
                "\n",
                "# æˆ‘ä»¬æ²¡æœ‰æåˆ° Shanghaiï¼ŒAgent å¿…é¡»ä»è®°å¿†ä¸­é€šè¿‡ USER_SESSION_ID æ‰¾å›ä¸Šä¸‹æ–‡\n",
                "chat_with_agent(\"æˆ‘é‚£é‡Œçš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\", thread_id=USER_SESSION_ID)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "å¦‚æœæˆåŠŸï¼ŒAgent åº”è¯¥ä¼šå›ç­”ä¸Šæµ·çš„å¤©æ°”ï¼Œå› ä¸ºå®ƒè®°ä½äº†ç¬¬ä¸€è½®å¯¹è¯çš„ Contextã€‚\n",
                "\n",
                "è¿™å°±æ˜¯ **Memory Bank** çš„æœ¬åœ°å®ç°åŸç†ï¼š**State Persistence (çŠ¶æ€æŒä¹…åŒ–)**ã€‚"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ§¹ ç¬¬å…­éƒ¨åˆ†ï¼šæ¸…ç†èµ„æº\n",
                "\n",
                "åœ¨äº‘ç«¯ï¼Œæˆ‘ä»¬éœ€è¦æ˜¾å¼åˆ é™¤ Agent Engine ä»¥é˜²æ‰£è´¹ã€‚åœ¨æœ¬åœ°ï¼Œæˆ‘ä»¬åªéœ€è¦åœæ­¢æœåŠ¡å™¨è¿›ç¨‹ã€‚\n",
                "\n",
                "1.  å›åˆ°ä½ çš„ç»ˆç«¯çª—å£ã€‚\n",
                "2.  æŒ‰ `Ctrl + C` åœæ­¢æœåŠ¡å™¨ã€‚\n",
                "3.  ä½ å¯ä»¥å®‰å…¨åœ°åˆ é™¤ç”Ÿæˆçš„ä¸´æ—¶æ–‡ä»¶ã€‚"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# å¯é€‰ï¼šæ¸…ç†ç”Ÿæˆçš„æ–‡ä»¶\n",
                "# !rm -rf serving\n",
                "print(\"âœ… æ•™ç¨‹ç»“æŸï¼\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸš€ æ€»ç»“ä¸ä¸‹ä¸€æ­¥\n",
                "\n",
                "æ­å–œï¼ä½ å®Œæˆäº† 5-Day Agent Course çš„æ‰€æœ‰å†…å®¹ï¼ˆLangChain ç‰ˆï¼‰ï¼ğŸ‰\n",
                "\n",
                "åœ¨ä»Šå¤©ï¼Œä½ å­¦ä¼šäº†ï¼š\n",
                "1.  ä½¿ç”¨ `LangGraph` å’Œ `MemorySaver` åˆ›å»ºå¸¦æœ‰æŒä¹…åŒ–è®°å¿†çš„ç”Ÿäº§çº§ Agentã€‚\n",
                "2.  ä½¿ç”¨ `FastAPI` æ˜¾å¼æ„å»º Agent æœåŠ¡ï¼Œç²¾ç¡®æ§åˆ¶å‚æ•°ä¼ é€’ã€‚\n",
                "3.  åœ¨æœ¬åœ°æ¨¡æ‹Ÿâ€œéƒ¨ç½²-è°ƒç”¨â€çš„å®Œæ•´é—­ç¯ï¼Œè§£å†³äº†å¤æ‚çš„é…ç½®é€ä¼ é—®é¢˜ã€‚\n",
                "\n",
                "ç°åœ¨ï¼Œä½ å¯ä»¥å°è¯•å°†ä½ çš„ Agent çœŸæ­£éƒ¨ç½²åˆ°æœåŠ¡å™¨ä¸Šï¼Œæˆ–è€…æ¢ç´¢æ›´å¤æ‚çš„ LangGraph æµç¨‹ï¼\n",
                "\n",
                "Happy Coding! ğŸš€"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (5-DAY-AGENT)",
            "language": "python",
            "name": "5-day-agent"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
